{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook, I will attempt to tweak the Convolutional Neural Network model provided in the sample notebook, and report my findings. The list of tweaks are listed as follow (keeping everything else default):<br>\n",
    "\n",
    "1) Fully connected layer output shape: (512, 256)(default) vs (256, 128) and (1024, 512)<br>\n",
    "2) Dropout rate: 0.2(default) vs 0.1 vs 0.5<br>\n",
    "3) 2 hiddenlayer vs 3 hiddenlayers: (512, 256)(default) vs [1024, 512, 256].<br>\n",
    "4) learning rate: 0.1(default) vs 0.3 and 0.1/epochs(time-based decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Python libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load some useful Python libraries:\n",
    "1. numpy: structural data types\n",
    "2. pandas: data loading and manipulation\n",
    "3. matplotlib, sns: data visualization\n",
    "4. sklearn: data analytics algorithms\n",
    "5. Tensorflow: Deep Learning library\n",
    "6. Keras: Wrapper for Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Activation\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.datasets import cifar10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data, perform reshape, normalization and one-hot encoding of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of final classes (in cifar10, there are 10 classes)\n",
    "nb_classes = 10\n",
    "nb_epoch = 100\n",
    "batch_size = 128\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "x_train = x_train.reshape(50000, 32 * 32 * 3)\n",
    "x_test = x_test.reshape(10000, 32 * 32 * 3)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255.0\n",
    "x_test /= 255.0\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define plot function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_acc(i, historyList):\n",
    "    fig = plt.figure()\n",
    "    for index, his in enumerate(historyList):\n",
    "        plt.plot(range(nb_epoch),his.history['acc'],label='training'+str(index))\n",
    "    plt.legend(loc=0)\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('training_accuracy')\n",
    "    plt.xlim([1,nb_epoch])\n",
    "    plt.grid(True)\n",
    "    plt.title(\"Training Accuracy Comparison\")\n",
    "    plt.show()\n",
    "    fig.savefig('img/'+str(i)+'-training-accuracy.png')\n",
    "    plt.close(fig)\n",
    "    \n",
    "def plot_val_acc(i, historyList):\n",
    "    fig = plt.figure()\n",
    "    for index, his in enumerate(historyList):\n",
    "        plt.plot(range(nb_epoch),his.history['val_acc'],label='validation'+str(index))\n",
    "    plt.legend(loc=0)\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('validation_accuracy')\n",
    "    plt.xlim([1,nb_epoch])\n",
    "    plt.grid(True)\n",
    "    plt.title(\"Validation Accuracy Comparison\")\n",
    "    plt.show()\n",
    "    fig.savefig('img/'+str(i)+'-validation-accuracy.png')\n",
    "    plt.close(fig)\n",
    "    \n",
    "def saveHistory(history, filename):\n",
    "    import json\n",
    "    json.dump(history.history, open('json_history/'+filename+'.json', 'w+'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Different Output Shape:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output shape refers to the number of neurons in each layer. In the sample, there are 4 layers:\n",
    "Input Layer, 2 hidden layers with output shape: 512 and 256 respectively, and an Output Layer with outputshape: 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define base model function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_shape(shape):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32,(3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate 3 different models with different output shapes and plot the graphs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer conv2d_1: expected ndim=4, found ndim=2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-8defd879c386>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodelDef\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCNN_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#default model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCNN_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCNN_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1024\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m historyDef = modelDef.fit(X_train, Y_train,\n",
      "\u001b[1;32m<ipython-input-4-b38e6e3bc821>\u001b[0m in \u001b[0;36mCNN_shape\u001b[1;34m(shape)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    163\u001b[0m                     \u001b[1;31m# and create the node connecting the current layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m                     \u001b[1;31m# to the input layer we just created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m                     \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m                     \u001b[0mset_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    412\u001b[0m                 \u001b[1;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m                 \u001b[1;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 414\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    415\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m                 \u001b[1;31m# Collect input shapes to build layer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m': expected ndim='\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m', found ndim='\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m                                      str(K.ndim(x)))\n\u001b[0m\u001b[0;32m    312\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 is incompatible with layer conv2d_1: expected ndim=4, found ndim=2"
     ]
    }
   ],
   "source": [
    "modelDef = CNN_shape(512) #default model\n",
    "model1 = CNN_shape(256)\n",
    "model2 = CNN_shape(1024)\n",
    "\n",
    "historyDef = modelDef.fit(X_train, Y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=nb_epoch,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, Y_test))\n",
    "saveHistory(historyDef,'historyDef_CNN')\n",
    "\n",
    "history1 = model1.fit(X_train, Y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=nb_epoch,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, Y_test))\n",
    "saveHistory(history1,'history1_CNN')\n",
    "\n",
    "history2 = model2.fit(X_train, Y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=nb_epoch,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, Y_test))\n",
    "saveHistory(history2,'history2_CNN')\n",
    "\n",
    "plot_train_acc(1, [historyDef, history1, history2])\n",
    "plot_val_acc(2, [historyDef, history1, history2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Different dropout rate:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define base model function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_drop_rate(drop_rate1, drop_rate2):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32,(3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(drop_rate1))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(drop_rate2))\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate 3 different models with different drop rate and plot the graphs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = MLP_drop_rate(0.1,0.3)\n",
    "model4 = MLP_drop_rate(0.5,0.5)\n",
    "\n",
    "history3 = model3.fit(X_train, Y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=nb_epoch,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, Y_test))\n",
    "saveHistory(history3,'history3_CNN')\n",
    "history4 = model4.fit(X_train, Y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=nb_epoch,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, Y_test))\n",
    "saveHistory(history4,'history4_CNN')\n",
    "\n",
    "plot_train_acc(3, [historyDef, history3, history4])\n",
    "plot_val_acc(4, [historyDef, history3, history4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Different number of layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 5 has 3 hiden layers\n",
    "model5 = Sequential()\n",
    "model5.add(Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:]))\n",
    "model5.add(Activation('relu'))\n",
    "model5.add(Conv2D(32,(3, 3)))\n",
    "model5.add(Activation('relu'))\n",
    "model5.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model5.add(Dropout(0.25))\n",
    "\n",
    "model5.add(Flatten())\n",
    "model5.add(Dense(512))\n",
    "model5.add(Activation('relu'))\n",
    "model5.add(Dropout(0.5))\n",
    "model5.add(Dense(256))\n",
    "model5.add(Activation('relu'))\n",
    "model5.add(Dropout(0.5))\n",
    "model5.add(Dense(nb_classes))\n",
    "model5.add(Activation('softmax'))\n",
    "\n",
    "model5.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "history5 = model5.fit(X_train, Y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=nb_epoch,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, Y_test))\n",
    "saveHistory(history5,'history5')\n",
    "           \n",
    "plot_train_acc(5 [historyDef, history5])\n",
    "plot_val_acc(6, [historyDef, history5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Different Learning Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define base model function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP_learningRate(lr, decay):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32,(3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    sgd = SGD(lr=lr, momentum=0.0, decay=decay, nesterov=False)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "    \n",
    "    #model.summary()\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6 = MLP_learningRate(0.3, 0.0)\n",
    "model7 = MLP_learningRate(0.1, 0.1/nb_epoch)\n",
    "\n",
    "history6 = model6.fit(X_train, Y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=nb_epoch,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, Y_test))\n",
    "saveHistory(history6,'history6')\n",
    "history7 = model7.fit(X_train, Y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=nb_epoch,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, Y_test))\n",
    "saveHistory(history7,'history7')\n",
    "\n",
    "plot_train_acc(7, [historyDef, history6, history7])\n",
    "plot_val_acc(8, [historyDef, history6, history7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Different Activation Functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define base model function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP_act_func(act_func):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32,(3, 3)))\n",
    "    model.add(Activation(act_func))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation(act_func))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "    #model.summary()\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model8 = MLP_act_func('sigmoid')\n",
    "model9 = MLP_act_func('prelu')\n",
    "model10 = MLP_act_func('softplus')\n",
    "\n",
    "history8 = model8.fit(X_train, Y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=nb_epoch,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, Y_test))\n",
    "saveHistory(history8,'history8')\n",
    "history9 = model9.fit(X_train, Y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=nb_epoch,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, Y_test))\n",
    "saveHistory(history9,'history9')\n",
    "history10 = model10.fit(X_train, Y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=nb_epoch,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, Y_test))\n",
    "saveHistory(history10,'history10')\n",
    "\n",
    "plot_train_acc(7, [historyDef, history8, history9, history10])\n",
    "plot_val_acc(8, [historyDef, history8, history9, history10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Different Loss Function:\n",
    "Since there are 10 classes in this dataset, 'categorical cross entropy' is the only option"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP_loss_func(loss_func):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32,(3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss=loss_func,\n",
    "                  optimizer='sgd',\n",
    "                  metrics=['accuracy'])\n",
    "    #model.summary()\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model11 = MLP_loss_func('sparse_categorical_crossentropy')\n",
    "\n",
    "\n",
    "history11 = model11.fit(X_train, Y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=nb_epoch,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, Y_test))\n",
    "saveHistory(history11,'history11')\n",
    "\n",
    "plot_train_acc(10, [historyDef, history11])\n",
    "plot_val_acc(12, [historyDef, history11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can add your analysis and results using these markdown cells.\n",
    "Some of the things you can play with for your models include\n",
    "1. Effects of varying number of hidden layers\n",
    "2. Effects of varying number of neurons in the hidden layers\n",
    "3. Effects of different learning rates\n",
    "4. Effects of other parameters (training method, activation function, loss function etc)\n",
    "\n",
    "You can also change the metric for classifier performance by using other measures such as mean squared error, confusion matrices etc.\n",
    "\n",
    "Here are some useful links for learning more about creating NN architectures:\n",
    "1. Keras - http://keras.io\n",
    "2. Tensorflow - http://www.tensorflow.org/\n",
    "3. Python numpy tutorial -  http://cs231n.github.io/python-numpy-tutorial/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
