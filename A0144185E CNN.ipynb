{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook, I will attempt to tweak the Convolutional Neural Network model provided in the sample notebook, and report my findings. The list of tweaks are listed as follow (keeping everything else default):<br>\n",
    "\n",
    "1) Application of Batch normalization<br>\n",
    "2) Different Drop-out rate<br>\n",
    "3) Different Learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Python libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load some useful Python libraries:\n",
    "1. numpy: structural data types\n",
    "2. pandas: data loading and manipulation\n",
    "3. matplotlib, sns: data visualization\n",
    "4. sklearn: data analytics algorithms\n",
    "5. Tensorflow: Deep Learning library\n",
    "6. Keras: Wrapper for Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Activation\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.datasets import cifar10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data, perform reshape, normalization and one-hot encoding of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of final classes (in cifar10, there are 10 classes)\n",
    "nb_classes = 10\n",
    "nb_epoch = 100\n",
    "batch_size = 128\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255.0\n",
    "x_test /= 255.0\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define plot function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_acc(i, historyList):\n",
    "    fig = plt.figure()\n",
    "    for index, his in enumerate(historyList):\n",
    "        plt.plot(range(nb_epoch),his.history['acc'],label='training'+str(index))\n",
    "    plt.legend(loc=0)\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('training_accuracy')\n",
    "    plt.xlim([1,nb_epoch])\n",
    "    plt.grid(True)\n",
    "    plt.title(\"Training Accuracy Comparison\")\n",
    "    plt.show()\n",
    "    fig.savefig('img/'+str(i)+'-training-accuracy_cnn.png')\n",
    "    plt.close(fig)\n",
    "    \n",
    "def plot_val_acc(i, historyList):\n",
    "    fig = plt.figure()\n",
    "    for index, his in enumerate(historyList):\n",
    "        plt.plot(range(nb_epoch),his.history['val_acc'],label='validation'+str(index))\n",
    "    plt.legend(loc=0)\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('validation_accuracy')\n",
    "    plt.xlim([1,nb_epoch])\n",
    "    plt.grid(True)\n",
    "    plt.title(\"Validation Accuracy Comparison\")\n",
    "    plt.show()\n",
    "    fig.savefig('img/'+str(i)+'-validation-accuracy_cnn.png')\n",
    "    plt.close(fig)\n",
    "    \n",
    "def saveHistory(history, filename):\n",
    "    import json\n",
    "    json.dump(history.history, open('json_history/'+filename+'.json', 'w+'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Applying Batch normalization on the default model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output shape refers to the number of neurons in each layer. In the sample, there are 4 layers:\n",
    "Input Layer, 2 hidden layers with output shape: 512 and 256 respectively, and an Output Layer with outputshape: 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create default CNN model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelDef = Sequential()\n",
    "modelDef.add(Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:]))\n",
    "modelDef.add(Activation('relu'))\n",
    "modelDef.add(Conv2D(32,(3, 3)))\n",
    "modelDef.add(Activation('relu'))\n",
    "modelDef.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "modelDef.add(Dropout(0.25))\n",
    "\n",
    "modelDef.add(Flatten())\n",
    "modelDef.add(Dense(512))\n",
    "modelDef.add(Activation('relu'))\n",
    "modelDef.add(Dropout(0.5))\n",
    "modelDef.add(Dense(nb_classes))\n",
    "modelDef.add(Activation('softmax'))\n",
    "\n",
    "modelDef.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "historyDef = modelDef.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=nb_epoch,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "saveHistory(historyDef,'historyDef_CNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create another model with batch normalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:]))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(Conv2D(32,(3, 3)))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model1.add(Dropout(0.25))\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(512))\n",
    "#adding batch normalization before activation function\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(nb_classes))\n",
    "model1.add(BatchNormalization())\n",
    "#adding batch normalization before activation function\n",
    "model1.add(Activation('softmax'))\n",
    "model1.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "history1 = model1.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=nb_epoch,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "saveHistory(history1,'history1_CNN')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the graphs to compare performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_acc(1, [historyDef, history1])\n",
    "plot_val_acc(2, [historyDef, history1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Different dropout rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define base model function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_drop_rate(drop_rate1, drop_rate2):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32,(3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(drop_rate1))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(drop_rate2))\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate 2 different models with different drop rate and plot the graphs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = CNN_drop_rate(0.1,0.3)\n",
    "model4 = CNN_drop_rate(0.5,0.5)\n",
    "\n",
    "history3 = model3.fit(X_train, Y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=nb_epoch,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, Y_test))\n",
    "saveHistory(history3,'history3_CNN')\n",
    "history4 = model4.fit(X_train, Y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=nb_epoch,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, Y_test))\n",
    "saveHistory(history4,'history4_CNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the graphs to compare performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_acc(3, [historyDef, history3, history4])\n",
    "plot_val_acc(4, [historyDef, history3, history4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Different learning rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define base model function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_learningRate(lr, decay):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32,(3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    sgd = SGD(lr=lr, momentum=0.0, decay=decay, nesterov=False)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "    \n",
    "    #model.summary()\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate 2 different models with different learning rate and plot the graphs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = CNN_learningRate(0.03, 0.0)\n",
    "model6 = CNN_learningRate(0.01, 0.01/nb_epoch)\n",
    "\n",
    "history5 = model6.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=nb_epoch,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "saveHistory(history5,'history5_CNN')\n",
    "history5 = model6.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=nb_epoch,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "saveHistory(history6,'history6_CNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the graphs to compare performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_acc(5, [historyDef, history5, history6])\n",
    "plot_val_acc(6, [historyDef, history5, history6])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
