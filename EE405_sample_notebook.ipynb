{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook, we explore neural network models for image classification using Tensorflow and Keras, along with some other important python libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load some useful Python libraries:\n",
    "1. numpy: structural data types\n",
    "2. pandas: data loading and manipulation\n",
    "3. matplotlib, sns: data visualization\n",
    "4. sklearn: data analytics algorithms\n",
    "5. Tensorflow: Deep Learning library\n",
    "6. Keras: Wrapper for Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Activation\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,707,274\n",
      "Trainable params: 1,707,274\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anhdt\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:39: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 20s 402us/step - loss: 2.0543 - acc: 0.2527 - val_loss: 1.8942 - val_acc: 0.3283\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 17s 336us/step - loss: 1.8795 - acc: 0.3297 - val_loss: 1.7986 - val_acc: 0.3591\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 17s 335us/step - loss: 1.8105 - acc: 0.3573 - val_loss: 1.7297 - val_acc: 0.3986\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 21s 413us/step - loss: 1.7637 - acc: 0.3750 - val_loss: 1.6993 - val_acc: 0.4022\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 19s 378us/step - loss: 1.7271 - acc: 0.3897 - val_loss: 1.6716 - val_acc: 0.4283\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 18s 367us/step - loss: 1.6930 - acc: 0.4037 - val_loss: 1.6260 - val_acc: 0.4307\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 17s 342us/step - loss: 1.6687 - acc: 0.4099 - val_loss: 1.5996 - val_acc: 0.4429\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 18s 358us/step - loss: 1.6449 - acc: 0.4182 - val_loss: 1.5914 - val_acc: 0.4411\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 18s 363us/step - loss: 1.6240 - acc: 0.4288 - val_loss: 1.5864 - val_acc: 0.4457\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 22s 436us/step - loss: 1.6072 - acc: 0.4368 - val_loss: 1.5550 - val_acc: 0.4569\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 21s 422us/step - loss: 1.5862 - acc: 0.4402 - val_loss: 1.5360 - val_acc: 0.4633\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 22s 442us/step - loss: 1.5737 - acc: 0.4472 - val_loss: 1.5261 - val_acc: 0.4645\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 24s 478us/step - loss: 1.5586 - acc: 0.4502 - val_loss: 1.5209 - val_acc: 0.4709 - ETA: 7s - loss: 1.5618 - acc: 0.4 - ETA: 7s - loss: 1.5612 - E - ETA: 4s - loss: 1.5612 - acc: 0 - ETA: 3s -\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 25s 492us/step - loss: 1.5432 - acc: 0.4571 - val_loss: 1.4957 - val_acc: 0.4767\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 20s 393us/step - loss: 1.5321 - acc: 0.4604 - val_loss: 1.4987 - val_acc: 0.4684\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 21s 430us/step - loss: 1.5195 - acc: 0.4669 - val_loss: 1.4821 - val_acc: 0.4741\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 16s 323us/step - loss: 1.5063 - acc: 0.4716 - val_loss: 1.5136 - val_acc: 0.4542\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 16s 313us/step - loss: 1.4935 - acc: 0.4745 - val_loss: 1.4763 - val_acc: 0.4764\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 16s 314us/step - loss: 1.4822 - acc: 0.4777 - val_loss: 1.4640 - val_acc: 0.4847\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 16s 312us/step - loss: 1.4706 - acc: 0.4814 - val_loss: 1.4418 - val_acc: 0.4920\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 16s 312us/step - loss: 1.4622 - acc: 0.4846 - val_loss: 1.4317 - val_acc: 0.4947\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 16s 314us/step - loss: 1.4519 - acc: 0.4894 - val_loss: 1.4454 - val_acc: 0.4838\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 16s 311us/step - loss: 1.4407 - acc: 0.4915 - val_loss: 1.4245 - val_acc: 0.4940\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 16s 313us/step - loss: 1.4347 - acc: 0.4960 - val_loss: 1.4048 - val_acc: 0.5045\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 16s 314us/step - loss: 1.4246 - acc: 0.5003 - val_loss: 1.4204 - val_acc: 0.5004\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 16s 330us/step - loss: 1.4176 - acc: 0.5009 - val_loss: 1.4290 - val_acc: 0.4976\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 22s 433us/step - loss: 1.4087 - acc: 0.5028 - val_loss: 1.4070 - val_acc: 0.5010 - loss: 1.4074 \n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 22s 430us/step - loss: 1.3999 - acc: 0.5076 - val_loss: 1.3906 - val_acc: 0.5086\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 19s 388us/step - loss: 1.3923 - acc: 0.5091 - val_loss: 1.4088 - val_acc: 0.5055\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 20s 406us/step - loss: 1.3847 - acc: 0.5119 - val_loss: 1.4275 - val_acc: 0.5025\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 19s 381us/step - loss: 1.3756 - acc: 0.5150 - val_loss: 1.3875 - val_acc: 0.5049\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 16s 328us/step - loss: 1.3704 - acc: 0.5169 - val_loss: 1.3882 - val_acc: 0.5089\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 18s 352us/step - loss: 1.3620 - acc: 0.5195 - val_loss: 1.3773 - val_acc: 0.5178 1s - loss: 1.3614\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 17s 349us/step - loss: 1.3547 - acc: 0.5225 - val_loss: 1.3640 - val_acc: 0.5241539 -\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 17s 330us/step - loss: 1.3457 - acc: 0.5275 - val_loss: 1.3730 - val_acc: 0.5161\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 22s 437us/step - loss: 1.3443 - acc: 0.5273 - val_loss: 1.3533 - val_acc: 0.5241\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 18s 358us/step - loss: 1.3345 - acc: 0.5311 - val_loss: 1.3732 - val_acc: 0.5223\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 15s 307us/step - loss: 1.3280 - acc: 0.5344 - val_loss: 1.3788 - val_acc: 0.5145\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 15s 310us/step - loss: 1.3211 - acc: 0.5359 - val_loss: 1.3453 - val_acc: 0.5208\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 17s 339us/step - loss: 1.3159 - acc: 0.5382 - val_loss: 1.3802 - val_acc: 0.5107\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 16s 316us/step - loss: 1.3064 - acc: 0.5394 - val_loss: 1.3515 - val_acc: 0.5230\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 16s 318us/step - loss: 1.2992 - acc: 0.5420 - val_loss: 1.3673 - val_acc: 0.5197\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 20s 391us/step - loss: 1.2950 - acc: 0.5419 - val_loss: 1.3415 - val_acc: 0.5256\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 21s 427us/step - loss: 1.2924 - acc: 0.5432 - val_loss: 1.3640 - val_acc: 0.5119\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 18s 353us/step - loss: 1.2851 - acc: 0.5462 - val_loss: 1.3275 - val_acc: 0.5316\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 16s 328us/step - loss: 1.2778 - acc: 0.5513 - val_loss: 1.3171 - val_acc: 0.5349\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 15s 309us/step - loss: 1.2723 - acc: 0.5528 - val_loss: 1.3346 - val_acc: 0.5296\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 17s 337us/step - loss: 1.2660 - acc: 0.5543 - val_loss: 1.3697 - val_acc: 0.5139\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 15s 309us/step - loss: 1.2603 - acc: 0.5568 - val_loss: 1.3323 - val_acc: 0.5253\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 16s 328us/step - loss: 1.2547 - acc: 0.5563 - val_loss: 1.3159 - val_acc: 0.5352\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 15s 306us/step - loss: 1.2486 - acc: 0.5616 - val_loss: 1.3392 - val_acc: 0.5247\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 17s 340us/step - loss: 1.2428 - acc: 0.5647 - val_loss: 1.3346 - val_acc: 0.5332\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 16s 327us/step - loss: 1.2377 - acc: 0.5665 - val_loss: 1.3228 - val_acc: 0.5335\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 16s 314us/step - loss: 1.2338 - acc: 0.5645 - val_loss: 1.3254 - val_acc: 0.5289\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 17s 342us/step - loss: 1.2271 - acc: 0.5671 - val_loss: 1.3093 - val_acc: 0.5329\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 16s 315us/step - loss: 1.2212 - acc: 0.5704 - val_loss: 1.3084 - val_acc: 0.5379\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 16s 320us/step - loss: 1.2183 - acc: 0.5713 - val_loss: 1.3393 - val_acc: 0.5150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 21s 426us/step - loss: 1.2108 - acc: 0.5713 - val_loss: 1.3319 - val_acc: 0.5295\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 22s 445us/step - loss: 1.2041 - acc: 0.5755 - val_loss: 1.2935 - val_acc: 0.5400\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 20s 392us/step - loss: 1.1995 - acc: 0.5772 - val_loss: 1.3302 - val_acc: 0.5318\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 19s 383us/step - loss: 1.1924 - acc: 0.5793 - val_loss: 1.3235 - val_acc: 0.5297\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 22s 446us/step - loss: 1.1903 - acc: 0.5809 - val_loss: 1.3199 - val_acc: 0.5313\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 19s 388us/step - loss: 1.1852 - acc: 0.5818 - val_loss: 1.2988 - val_acc: 0.5408845 -\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 19s 386us/step - loss: 1.1879 - acc: 0.5813 - val_loss: 1.2811 - val_acc: 0.5470\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 24s 477us/step - loss: 1.1770 - acc: 0.5847 - val_loss: 1.2988 - val_acc: 0.5393\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.1719 - acc: 0.5895 - val_loss: 1.3160 - val_acc: 0.5217\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.1647 - acc: 0.5887 - val_loss: 1.3273 - val_acc: 0.5297\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 20s 391us/step - loss: 1.1604 - acc: 0.5914 - val_loss: 1.2758 - val_acc: 0.5467\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 18s 353us/step - loss: 1.1600 - acc: 0.5915 - val_loss: 1.3058 - val_acc: 0.5398\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 18s 352us/step - loss: 1.1537 - acc: 0.5933 - val_loss: 1.2901 - val_acc: 0.5381\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 18s 353us/step - loss: 1.1458 - acc: 0.5947 - val_loss: 1.2957 - val_acc: 0.5388\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 18s 352us/step - loss: 1.1415 - acc: 0.5942 - val_loss: 1.2996 - val_acc: 0.5395\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 18s 360us/step - loss: 1.1378 - acc: 0.6006 - val_loss: 1.2975 - val_acc: 0.5446\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 18s 350us/step - loss: 1.1346 - acc: 0.6007 - val_loss: 1.3019 - val_acc: 0.5460\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 18s 354us/step - loss: 1.1297 - acc: 0.5998 - val_loss: 1.2683 - val_acc: 0.5530\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 18s 366us/step - loss: 1.1267 - acc: 0.6015 - val_loss: 1.2794 - val_acc: 0.5425\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 17s 348us/step - loss: 1.1246 - acc: 0.6047 - val_loss: 1.2804 - val_acc: 0.5459\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 17s 348us/step - loss: 1.1177 - acc: 0.6070 - val_loss: 1.2992 - val_acc: 0.5387\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 19s 380us/step - loss: 1.1157 - acc: 0.6069 - val_loss: 1.3611 - val_acc: 0.5147\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 18s 364us/step - loss: 1.1092 - acc: 0.6070 - val_loss: 1.2894 - val_acc: 0.5419\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 18s 355us/step - loss: 1.1033 - acc: 0.6103 - val_loss: 1.2692 - val_acc: 0.5495\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 18s 356us/step - loss: 1.1063 - acc: 0.6118 - val_loss: 1.2856 - val_acc: 0.5449\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 17s 349us/step - loss: 1.0971 - acc: 0.6126 - val_loss: 1.2986 - val_acc: 0.5434\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 18s 350us/step - loss: 1.0910 - acc: 0.6145 - val_loss: 1.2991 - val_acc: 0.5439\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 17s 350us/step - loss: 1.0903 - acc: 0.6145 - val_loss: 1.2613 - val_acc: 0.5559\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 18s 352us/step - loss: 1.0870 - acc: 0.6151 - val_loss: 1.2970 - val_acc: 0.5456\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 18s 354us/step - loss: 1.0774 - acc: 0.6191 - val_loss: 1.2946 - val_acc: 0.5457\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 18s 355us/step - loss: 1.0767 - acc: 0.6210 - val_loss: 1.3219 - val_acc: 0.5361\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 18s 356us/step - loss: 1.0691 - acc: 0.6225 - val_loss: 1.2741 - val_acc: 0.5485\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 17s 350us/step - loss: 1.0675 - acc: 0.6220 - val_loss: 1.2738 - val_acc: 0.5529\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 18s 356us/step - loss: 1.0596 - acc: 0.6253 - val_loss: 1.2570 - val_acc: 0.5589\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 18s 357us/step - loss: 1.0602 - acc: 0.6240 - val_loss: 1.2805 - val_acc: 0.5456\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 18s 362us/step - loss: 1.0539 - acc: 0.6273 - val_loss: 1.3432 - val_acc: 0.5352\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 19s 388us/step - loss: 1.0492 - acc: 0.6301 - val_loss: 1.3176 - val_acc: 0.5411\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 19s 371us/step - loss: 1.0484 - acc: 0.6312 - val_loss: 1.2955 - val_acc: 0.5461\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 18s 365us/step - loss: 1.0397 - acc: 0.6337 - val_loss: 1.3308 - val_acc: 0.5341\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 22s 433us/step - loss: 1.0406 - acc: 0.6321 - val_loss: 1.2922 - val_acc: 0.5466\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 20s 394us/step - loss: 1.0372 - acc: 0.6347 - val_loss: 1.2798 - val_acc: 0.5470\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 19s 373us/step - loss: 1.0302 - acc: 0.6353 - val_loss: 1.3063 - val_acc: 0.5430\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 19s 371us/step - loss: 1.0279 - acc: 0.6353 - val_loss: 1.3043 - val_acc: 0.5425\n",
      "Test loss: 1.3043016260147096\n",
      "Test acc: 0.5425\n"
     ]
    }
   ],
   "source": [
    "nb_epoch = 100\n",
    "batch_size = 128\n",
    "nb_classes = 10\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "X_train = X_train.reshape(50000, 32 * 32 * 3)\n",
    "X_test = X_test.reshape(10000, 32 * 32 * 3)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "# MLP\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=X_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# training\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    nb_epoch=nb_epoch,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, Y_test))\n",
    "\n",
    "loss, acc = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test loss:', loss)\n",
    "print('Test acc:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonedModel = model.to_json()\n",
    "with open(\"MLP_model_sample.json\", \"w+\") as json_file:\n",
    "    json_file.write(jsonedModel)\n",
    "    \n",
    "model.save_weights(\"MLP_model_sample.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 7200)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               3686912   \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 3,702,186\n",
      "Trainable params: 3,702,186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 248s 5ms/step - loss: 2.1129 - acc: 0.2206 - val_loss: 1.9150 - val_acc: 0.3263\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 218s 4ms/step - loss: 1.8975 - acc: 0.3199 - val_loss: 1.7517 - val_acc: 0.3919\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 219s 4ms/step - loss: 1.7843 - acc: 0.3670 - val_loss: 1.6775 - val_acc: 0.4169\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 221s 4ms/step - loss: 1.7029 - acc: 0.3936 - val_loss: 1.5849 - val_acc: 0.4443\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 217s 4ms/step - loss: 1.6388 - acc: 0.4170 - val_loss: 1.5179 - val_acc: 0.4666\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 218s 4ms/step - loss: 1.5821 - acc: 0.4368 - val_loss: 1.4728 - val_acc: 0.4805\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 219s 4ms/step - loss: 1.5367 - acc: 0.4531 - val_loss: 1.4502 - val_acc: 0.4833\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 213s 4ms/step - loss: 1.4980 - acc: 0.4671 - val_loss: 1.4067 - val_acc: 0.5065\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 213s 4ms/step - loss: 1.4655 - acc: 0.4781 - val_loss: 1.3757 - val_acc: 0.5192\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 213s 4ms/step - loss: 1.4308 - acc: 0.4881 - val_loss: 1.3391 - val_acc: 0.5310\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 214s 4ms/step - loss: 1.3999 - acc: 0.5008 - val_loss: 1.3130 - val_acc: 0.5348\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 213s 4ms/step - loss: 1.3702 - acc: 0.5090 - val_loss: 1.2930 - val_acc: 0.5440\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 216s 4ms/step - loss: 1.3407 - acc: 0.5223 - val_loss: 1.2551 - val_acc: 0.5581\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 214s 4ms/step - loss: 1.3132 - acc: 0.5309 - val_loss: 1.2793 - val_acc: 0.5546\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 214s 4ms/step - loss: 1.2896 - acc: 0.5434 - val_loss: 1.2203 - val_acc: 0.5672\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 214s 4ms/step - loss: 1.2712 - acc: 0.5480 - val_loss: 1.1992 - val_acc: 0.5770\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 214s 4ms/step - loss: 1.2448 - acc: 0.5579 - val_loss: 1.1805 - val_acc: 0.5832\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 213s 4ms/step - loss: 1.2238 - acc: 0.5645 - val_loss: 1.1769 - val_acc: 0.5843\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 215s 4ms/step - loss: 1.2092 - acc: 0.5705 - val_loss: 1.1459 - val_acc: 0.5958\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 213s 4ms/step - loss: 1.1894 - acc: 0.5772 - val_loss: 1.1335 - val_acc: 0.6002\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 214s 4ms/step - loss: 1.1719 - acc: 0.5858 - val_loss: 1.1227 - val_acc: 0.6065\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 214s 4ms/step - loss: 1.1560 - acc: 0.5919 - val_loss: 1.1516 - val_acc: 0.5961\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 213s 4ms/step - loss: 1.1385 - acc: 0.5955 - val_loss: 1.0989 - val_acc: 0.6090\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 214s 4ms/step - loss: 1.1233 - acc: 0.6018 - val_loss: 1.0914 - val_acc: 0.6149\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 213s 4ms/step - loss: 1.1080 - acc: 0.6094 - val_loss: 1.1045 - val_acc: 0.6117\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 213s 4ms/step - loss: 1.0938 - acc: 0.6122 - val_loss: 1.0741 - val_acc: 0.6263\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 213s 4ms/step - loss: 1.0776 - acc: 0.6183 - val_loss: 1.0633 - val_acc: 0.6244\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 213s 4ms/step - loss: 1.0612 - acc: 0.6248 - val_loss: 1.0659 - val_acc: 0.6245\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 213s 4ms/step - loss: 1.0523 - acc: 0.6291 - val_loss: 1.0344 - val_acc: 0.6352\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 215s 4ms/step - loss: 1.0333 - acc: 0.6349 - val_loss: 1.0285 - val_acc: 0.6384\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 214s 4ms/step - loss: 1.0228 - acc: 0.6388 - val_loss: 1.0176 - val_acc: 0.6399\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 215s 4ms/step - loss: 1.0090 - acc: 0.6444 - val_loss: 1.0063 - val_acc: 0.6454\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 214s 4ms/step - loss: 0.9968 - acc: 0.6470 - val_loss: 1.0074 - val_acc: 0.6466\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 213s 4ms/step - loss: 0.9824 - acc: 0.6533 - val_loss: 0.9876 - val_acc: 0.6535\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 214s 4ms/step - loss: 0.9705 - acc: 0.6582 - val_loss: 0.9861 - val_acc: 0.6509\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 214s 4ms/step - loss: 0.9596 - acc: 0.6601 - val_loss: 0.9757 - val_acc: 0.6562\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 213s 4ms/step - loss: 0.9472 - acc: 0.6640 - val_loss: 0.9746 - val_acc: 0.6539\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 214s 4ms/step - loss: 0.9328 - acc: 0.6691 - val_loss: 0.9651 - val_acc: 0.6605\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 213s 4ms/step - loss: 0.9221 - acc: 0.6763 - val_loss: 0.9646 - val_acc: 0.6569\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 213s 4ms/step - loss: 0.9131 - acc: 0.6775 - val_loss: 0.9634 - val_acc: 0.6601\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 213s 4ms/step - loss: 0.8997 - acc: 0.6810 - val_loss: 0.9728 - val_acc: 0.6555\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 213s 4ms/step - loss: 0.8866 - acc: 0.6840 - val_loss: 0.9407 - val_acc: 0.6694\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 213s 4ms/step - loss: 0.8783 - acc: 0.6922 - val_loss: 0.9508 - val_acc: 0.6634\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 213s 4ms/step - loss: 0.8657 - acc: 0.6961 - val_loss: 0.9507 - val_acc: 0.6633\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 212s 4ms/step - loss: 0.8564 - acc: 0.6986 - val_loss: 0.9217 - val_acc: 0.6740\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 213s 4ms/step - loss: 0.8439 - acc: 0.7029 - val_loss: 0.9239 - val_acc: 0.6716\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 214s 4ms/step - loss: 0.8297 - acc: 0.7084 - val_loss: 0.9130 - val_acc: 0.6801\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 216s 4ms/step - loss: 0.8236 - acc: 0.7095 - val_loss: 0.9053 - val_acc: 0.6791\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 220s 4ms/step - loss: 0.8126 - acc: 0.7135 - val_loss: 0.9011 - val_acc: 0.6844\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 218s 4ms/step - loss: 0.7999 - acc: 0.7190 - val_loss: 0.8962 - val_acc: 0.6887\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 214s 4ms/step - loss: 0.7912 - acc: 0.7227 - val_loss: 0.9089 - val_acc: 0.6822\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 212s 4ms/step - loss: 0.7816 - acc: 0.7241 - val_loss: 0.8999 - val_acc: 0.6804\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 212s 4ms/step - loss: 0.7712 - acc: 0.7264 - val_loss: 0.8823 - val_acc: 0.6925\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 212s 4ms/step - loss: 0.7588 - acc: 0.7297 - val_loss: 0.8889 - val_acc: 0.6884\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 212s 4ms/step - loss: 0.7526 - acc: 0.7341 - val_loss: 0.8879 - val_acc: 0.6890\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 212s 4ms/step - loss: 0.7442 - acc: 0.7351 - val_loss: 0.8722 - val_acc: 0.6946\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 212s 4ms/step - loss: 0.7325 - acc: 0.7423 - val_loss: 0.8751 - val_acc: 0.6931\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 211s 4ms/step - loss: 0.7232 - acc: 0.7466 - val_loss: 0.8745 - val_acc: 0.6931\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 212s 4ms/step - loss: 0.7181 - acc: 0.7467 - val_loss: 0.8650 - val_acc: 0.6992\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 214s 4ms/step - loss: 0.6994 - acc: 0.7539 - val_loss: 0.8722 - val_acc: 0.6940\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 212s 4ms/step - loss: 0.6974 - acc: 0.7535 - val_loss: 0.8581 - val_acc: 0.6955\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 212s 4ms/step - loss: 0.6854 - acc: 0.7557 - val_loss: 0.8803 - val_acc: 0.6942\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 214s 4ms/step - loss: 0.6811 - acc: 0.7586 - val_loss: 0.8556 - val_acc: 0.7009\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 212s 4ms/step - loss: 0.6683 - acc: 0.7634 - val_loss: 0.8555 - val_acc: 0.7026\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 212s 4ms/step - loss: 0.6604 - acc: 0.7661 - val_loss: 0.8548 - val_acc: 0.7013\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 213s 4ms/step - loss: 0.6464 - acc: 0.7699 - val_loss: 0.8517 - val_acc: 0.7036\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 212s 4ms/step - loss: 0.6410 - acc: 0.7738 - val_loss: 0.8486 - val_acc: 0.7048\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 212s 4ms/step - loss: 0.6343 - acc: 0.7748 - val_loss: 0.8480 - val_acc: 0.7044\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 214s 4ms/step - loss: 0.6201 - acc: 0.7804 - val_loss: 0.8548 - val_acc: 0.7021\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 212s 4ms/step - loss: 0.6134 - acc: 0.7837 - val_loss: 0.8539 - val_acc: 0.7054\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 212s 4ms/step - loss: 0.6068 - acc: 0.7857 - val_loss: 0.8413 - val_acc: 0.7070\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 214s 4ms/step - loss: 0.5952 - acc: 0.7880 - val_loss: 0.8390 - val_acc: 0.7123\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 214s 4ms/step - loss: 0.5901 - acc: 0.7903 - val_loss: 0.8456 - val_acc: 0.7073\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 213s 4ms/step - loss: 0.5808 - acc: 0.7942 - val_loss: 0.8466 - val_acc: 0.7071\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 212s 4ms/step - loss: 0.5768 - acc: 0.7952 - val_loss: 0.8547 - val_acc: 0.7062\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 212s 4ms/step - loss: 0.5610 - acc: 0.8007 - val_loss: 0.8403 - val_acc: 0.7084\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 213s 4ms/step - loss: 0.5572 - acc: 0.8016 - val_loss: 0.8443 - val_acc: 0.7116\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 212s 4ms/step - loss: 0.5484 - acc: 0.8052 - val_loss: 0.8378 - val_acc: 0.7117\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 212s 4ms/step - loss: 0.5416 - acc: 0.8080 - val_loss: 0.8385 - val_acc: 0.7114\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 214s 4ms/step - loss: 0.5296 - acc: 0.8151 - val_loss: 0.8413 - val_acc: 0.7094\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 212s 4ms/step - loss: 0.5266 - acc: 0.8117 - val_loss: 0.8497 - val_acc: 0.7041\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 212s 4ms/step - loss: 0.5135 - acc: 0.8172 - val_loss: 0.8393 - val_acc: 0.7137\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 213s 4ms/step - loss: 0.5106 - acc: 0.8178 - val_loss: 0.8463 - val_acc: 0.7112\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 212s 4ms/step - loss: 0.5010 - acc: 0.8216 - val_loss: 0.8311 - val_acc: 0.7118\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 212s 4ms/step - loss: 0.4947 - acc: 0.8249 - val_loss: 0.8370 - val_acc: 0.7124\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 214s 4ms/step - loss: 0.4848 - acc: 0.8278 - val_loss: 0.8371 - val_acc: 0.7153\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 213s 4ms/step - loss: 0.4843 - acc: 0.8301 - val_loss: 0.8359 - val_acc: 0.7172\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 213s 4ms/step - loss: 0.4738 - acc: 0.8317 - val_loss: 0.8366 - val_acc: 0.7172\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 212s 4ms/step - loss: 0.4689 - acc: 0.8324 - val_loss: 0.8314 - val_acc: 0.7195\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 213s 4ms/step - loss: 0.4636 - acc: 0.8377 - val_loss: 0.8334 - val_acc: 0.7167\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 212s 4ms/step - loss: 0.4528 - acc: 0.8386 - val_loss: 0.8466 - val_acc: 0.7143\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 212s 4ms/step - loss: 0.4439 - acc: 0.8418 - val_loss: 0.8546 - val_acc: 0.7113\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 213s 4ms/step - loss: 0.4389 - acc: 0.8438 - val_loss: 0.8443 - val_acc: 0.7164\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 213s 4ms/step - loss: 0.4340 - acc: 0.8449 - val_loss: 0.8396 - val_acc: 0.7166\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 213s 4ms/step - loss: 0.4304 - acc: 0.8472 - val_loss: 0.8457 - val_acc: 0.7177\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 213s 4ms/step - loss: 0.4210 - acc: 0.8502 - val_loss: 0.8436 - val_acc: 0.7191\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 215s 4ms/step - loss: 0.4146 - acc: 0.8520 - val_loss: 0.8432 - val_acc: 0.7209\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 213s 4ms/step - loss: 0.4116 - acc: 0.8530 - val_loss: 0.8564 - val_acc: 0.7179\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 215s 4ms/step - loss: 0.4056 - acc: 0.8543 - val_loss: 0.8442 - val_acc: 0.7223\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 214s 4ms/step - loss: 0.4010 - acc: 0.8557 - val_loss: 0.8438 - val_acc: 0.7241\n",
      "Test loss: 0.8437670932769775\n",
      "Test acc: 0.7241\n"
     ]
    }
   ],
   "source": [
    "# Retrieving Data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Declare variables\n",
    "\n",
    "nb_epoch = 100\n",
    "batch_size = 128\n",
    "nb_classes = 10\n",
    "\n",
    "# Convert and pre-processing\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train  /= 255\n",
    "x_test /= 255\n",
    "\n",
    "def base_model():\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32,(3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    sgd = SGD()\n",
    "\n",
    "# Train model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "cnn_n = base_model()\n",
    "cnn_n.summary()\n",
    "\n",
    "# Fit model\n",
    "\n",
    "cnn = cnn_n.fit(x_train, y_train, batch_size=batch_size, epochs=nb_epoch, validation_data=(x_test,y_test),shuffle=True)\n",
    "loss, acc = cnn_n.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', loss)\n",
    "print('Test acc:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonedModel = cnn_n.to_json()\n",
    "with open(\"CNN_model_sample.json\", \"w+\") as json_file:\n",
    "    json_file.write(jsonedModel)\n",
    "    \n",
    "cnn_n.save_weights(\"CNN_model_sample.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can add your analysis and results using these markdown cells.\n",
    "Some of the things you can play with for your models include\n",
    "1. Effects of varying number of hidden layers\n",
    "2. Effects of varying number of neurons in the hidden layers\n",
    "3. Effects of different learning rates\n",
    "4. Effects of other parameters (training method, activation function, loss function etc)\n",
    "\n",
    "You can also change the metric for classifier performance by using other measures such as mean squared error, confusion matrices etc.\n",
    "\n",
    "Here are some useful links for learning more about creating NN architectures:\n",
    "1. Keras - http://keras.io\n",
    "2. Tensorflow - http://www.tensorflow.org/\n",
    "3. Python numpy tutorial -  http://cs231n.github.io/python-numpy-tutorial/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
